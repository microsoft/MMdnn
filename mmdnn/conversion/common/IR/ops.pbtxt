op {
  name: "Add"
  input_arg {
    name: "x"
    type_attr: "T"
  }
  input_arg {
    name: "y"
    type_attr: "T"
  }
  output_arg {
    name: "z"
    type_attr: "T"
  }
  attr {
    name: "axis"
    type: "int"
  }
  summary: "Returns x + y element-wise."
  description: "*NOTE*: `Add` supports broadcasting."
}


op {
  name: "BatchNorm"
  attr {
      name: "axis"
      type: "int"
      description: "The axis that should be normalized (typically the features axis). For instance, after a Convolution2D layer with data_format="channels_first", set axis=1 in BatchNormalization"
  }
  attr {
      name: "momentum"
      type: "float"
      default_value {
        f: 0.99
      }
      description: "Momentum for the moving average."
  }
  attr {
    name: "epsilon"
    type: "float"
    default_value {
      f: 0.0001
    }
  }
  attr {
      name: "scale"
      type: "bool"
      default_value {
        b: True
      }
      description: "If True, multiply by gamma. If False, gamma is not used. When the next layer is linear (also e.g. nn.relu), this can be disabled since the scaling can be done by the next layer."
  }
  attr {
    name: "bias"
    type: "bool"
    default_value {
        b: True
      }
    description: " If True, add offset of beta to normalized tensor. If False, beta is ignored."
  }
  attr {
    name: "data_format"
    type: "string"
    default_value {
      s: "NHWC"
    }
    description: "The data format for x and y. Either 'NHWC' (default) or 'NCHW'."
  }
  attr {
    name: "is_training"
    type: "bool"
    default_value {
      b: true
    }
    description: "A bool value to indicate the operation is for training (default) or inference."
  }
  summary: "tf.layers.batch_normalization"
  description: "Follow Keras FusedBatchNorm, parameters are [scale], [bias], [mean], [var]."
}


op {
  name: "Concat"
  attr {
    name: "axis"
    type: "int"
  }
  summary: "Concatenates tensors along one dimension."
}


op {
  name: "Crop"
  attr {
    name: "border"
    type: "list(int). A 1-D values of (leftBorder, topBorder, rightBorder, bottomBorder)."
  }
  summary: "Crop and image to the specified spatial dimensions."
}


op {
  name: "Conv"
  attr {
    name: "use_bias"
    type: "bool"
    default_value {
      b: true
    }
    description: "If use bias"
    }
  }
  attr {
    name: "dilations"
    type: "list(int)"
    description: "Sequence of N ints >= 1. Specifies the filter upsampling/input downsampling rate. [1, dilation_depth, dilation_height, dilation_width, 1]"
  }
  attr {
    name: "kernel_shape"
    description: "The shape of the convolution kernel. [filter_depth, filter_height, filter_width, in_channels, out_channels]"
    type: "list(int)"
  }
  attr {
    name: "strides"
    type: "list(int)"
    description: "1-D tensor of length N.  [1, stride_deep, stride_height, stride_width, 1]"
  }
  attr {
    name: "pads"
    type: "list(int)"
    description: "1-D tensor of length N*2. [x1_begin, x2_begin...x1_end, x2_end,...]"
  }
  attr {
    name: "group"
    type: "int"
    default_value {
      i: 1
    }
    description: "If g > 1, we restrict the connectivity of each filter to a subset of the input. Specifically, the input and output channels are separated into g groups, and the iith output group channels will be only connected to the iith input group channels."
  }
  attr {
    name: "auto_pad"
    type: "string"
    description: "The type of padding algorithm to use. Where SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding."
    allowed_values {
      list {
        s: "SAME_UPPER"
        s: "SAME_LOWER"
        s: "VALID"
      }
    }
  }
  attr {
    name: "data_format"
    type: "string"
    default_value {
      s: "NHWC"
    }
    allowed_values {
      list {
        s: "NC"
        s: "NWC"
        s: "NCW"
        s: "NHWC"
        s: "NCHW"
        s: "NDHWC"
        s: "NCDHW"
      }
    }
  }
  summary: "Computes a (N-2)-D convolution given N-D `input` and `filter` tensors."
  description: "Parameters are [weights] and [bias]. Given an input tensor of shape `[batch, in_depth, in_height, in_width, in_channels]` and a filter kernel tensor of shape `[filter_height, filter_width, in_channels, out_channels]`, this op performs the following:1. Flattens the filter to a 2-D matrix with shape `[filter_height * filter_width * in_channels, output_channels]`. 2. Extracts image patches from the input tensor to form a *virtual* tensor of shape `[batch, out_height, out_width, filter_height * filter_width * in_channels]`. 3. For each patch, right-multiplies the filter matrix and the image patch vector. In detail, with the default NHWC format, output[b, i, j, k] = sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] * filter[di, dj, q, k] Must have `strides[0] = strides[3] = 1`.  For the most common case of the same horizontal and vertices strides, `strides = [1, stride, stride, 1]`."
}

op {
  name: "ConvTranspose"
  attr {
    name: "kernel_shape"
    description: "Shape [filter_depth, filter_height, filter_width, out_channels, in_channels]. Follow tensorflow conv2d_transpose args."
    type: "list(int)"
  }
  attr {
    name: "strides"
    type: "list(int)"
    description: "1-D tensor of length N.  [1, stride_deep, stride_height, stride_width, 1]"
  }
  attr {
    name: "group"
    type: "int"
    default_value {
      i: 1
    }
    description: "If g > 1, we restrict the connectivity of each filter to a subset of the input. Specifically, the input and output channels are separated into g groups, and the iith output group channels will be only connected to the iith input group channels."
  }
  attr {
    name: "auto_pad"
    type: "string"
    description: "The type of padding algorithm to use. Where SAME_UPPER or SAME_LOWER mean pad the input so that the output size match the input.In case of odd number add the extra padding at the end for SAME_UPPER and at the beginning for SAME_LOWER. VALID mean no padding."
    allowed_values {
      list {
        s: "SAME_UPPER"
        s: "SAME_LOWER"
        s: "VALID"
      }
    }
  }
  attr {
    name: "pads"
    type: "list(int)"
    description: "1-D tensor of length N*2. [x1_begin, x2_begin...x1_end, x2_end,...]"
  }
  attr {
    name: "data_format"
    type: "string"
    default_value {
      s: "NHWC"
    }
    allowed_values {
      list {
        s: "NC"
        s: "NWC"
        s: "NCW"
        s: "NHWC"
        s: "NCHW"
        s: "NDHWC"
        s: "NCDHW"
      }
    }
  }
  summary: "Computes a (N-2)-D convolution given N-D `input` and `filter` tensors."
  description: "Given an input tensor of shape `[batch, in_depth, in_height, in_width, in_channels]` and a filter / kernel tensor of shape `[filter_height, filter_width, in_channels, out_channels]`, this op performs the following:1. Flattens the filter to a 2-D matrix with shape `[filter_height * filter_width * in_channels, output_channels]`. 2. Extracts image patches from the input tensor to form a *virtual* tensor of shape `[batch, out_height, out_width, filter_height * filter_width * in_channels]`. 3. For each patch, right-multiplies the filter matrix and the image patch vector. In detail, with the default NHWC format, output[b, i, j, k] = sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q] * filter[di, dj, q, k] Must have `strides[0] = strides[3] = 1`.  For the most common case of the same horizontal and vertices strides, `strides = [1, stride, stride, 1]`."
}


op {
  name: "DataInput"
  attr {
    name: "dtype"
    type: "type"
    description: "The type of elements in the tensor."
  }
  attr {
    name: "shape"
    type: "shape"
    description: "The shape of the tensor."
  }
  summary: "Input Data Layer."
}


op {
  name: "Div"
  attr {
    name: "axis"
    type: "int"
  }
  summary: "Performs element-wise binary division."
}


op {
  name: "Dropout"
  attr {
    name: "keep_prob"
    type: "float"
  }
  attr {
    name: "seed"
    type: "int"
  }
  attr {
    name: "noise_shape"
    type: "list(int)"
  }
  summary: "Dropout Layer"
  description: "With probability keep_prob, outputs the input element scaled up by 1 / keep_prob, otherwise outputs 0. The scaling is so that the expected sum is unchanged."
}


op {
  name: "Exp"
  input_arg {
    name: "x"
  }
  output_arg {
    name: "y"
  }
  summary: "Computes exponential of x element-wise.  y = e^x."
}


op {
  name: "Flatten"
  summary: "Flatten Layer."
  description: "Not directly mapping in Tensorflow. Flatten tensor with shape [batch_size, k]."
}


op {
  name: "FullyConnected"
  attr {
    name: "units"
    type: "int"
  }
  attr {
    name: "use_bias"
    type: "bool"
    default_value {
      b: true
    }
    description: "If use bias"
    }
  }
  summary: "Y = W * X + b"
  description: "Not in Tensorflow. Dense operator in Keras. parameters are [weights], [bias]."
}


op {
  name: "Gather"
  input_arg {
    name: "params"
    description: "The tensor from which to gather values. Must be at least rank `axis + 1`."
  }
  input_arg {
    name: "indices"
    description: "Index tensor. Must be in range `[0, params.shape[axis])`."
  }
  output_arg {
    name: "output"
    description: "Values from `params` gathered from indices given by `indices`, with shape `params.shape[:axis] + indices.shape + params.shape[axis + 1:]`."
  }
  attr {
    name: "axis"
    description: "The axis in `params` to gather `indices` from. Defaults to the first dimension. Supports negative indexes."
    type: "int"
  }
  attr {
    name: "input_dim"
    description: "For Embedding layer. Size of the input vocabulary."
    type: "int"
  }
  attr {
    name: "output_dim"
    description: "For Embedding layer. Dimension of the embedding output vectors."
    type: "int"
  }
  summary: "Gather slices from `params` axis `axis` according to `indices`."
  description: "`indices` must be an integer tensor of any dimension (usually 0-D or 1-D). Produces an output tensor with shape `params.shape[:axis] + indices.shape + params.shape[axis + 1:]`"
}


op {
  name: "Log"
  input_arg {
    name: "x"
  }
  output_arg {
    name: "y"
  }
  summary: "Computes natural logarithm of x element-wise."
  description: "I.e., y = log_e(x)."
}


op {
  name: "Matmul"
  summary: "Matrix product that behaves like numpy.matmul."
}


op {
  name: "Mul"
  attr {
    name: "axis"
    type: "int"
  }
  summary: "Performs element-wise binary multiplication."
}


op {
  name: "Reciprocal"
  input_arg {
    name: "x"
  }
  output_arg {
    name: "y"
  }
  summary: "Computes the reciprocal of x element-wise."
  description: "I.e., (y = 1 / x)."
}


op {
  name: "Relu"
  summary: "Computes rectified linear: `max(features, 0)`."
}

op {
  name: "Relu6"
  summary: "Computes rectified linear 6: `min(max(features, 0), 6)`."
}


op {
  name: "Softmax"
  attr {
    name: "dim"
    type: "int"
    default_value {
      i: -1
    }
  }
  summary: "Computes softmax activations."
  description: "softmax = exp(logits) / reduce_sum(exp(logits), dim)"
}

op {
  name: "Sigmoid"
  summary: "Computes sigmoid of `x` element-wise."
  description: "Specifically, `y = 1 / (1 + exp(-x))`."
}

op {
  name: "Tanh"
  summary: "Computes hyperbolic tangent of `x` element-wise."
}

op {
  name: "Elu"
  attr {
    name: "alpha"
    type: "float"
    default_value {
      f: 1.0
    }
  }
  summary: "Computes exponential linear: `exp(features) - alpha` if < 0, `features` otherwise."
  description: "Not directly supported alpha in Tensorflow. See [Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)](http://arxiv.org/abs/1511.07289)"
}


op {
  name: "Pad"
  attr {
    name: "paddings"
    type: "list(int)"
    description: "integer tensor with shape N * 2."
  }

  attr {
    name: "mode"
    type: "string"
    allowed_values {
      list {
        s: "CONSTANT"
        s: "REFLECT"
        s: "SYMMETRIC"
      }
    }
    attr {
      name: "constant_values"
      type: "float"
    }
  }
  summary: "Padding Layer."
  description: "Not directly mapping in Tensorflow. Pads a tensor."
}

op {
  name: "Pool"
  attr {
    name: "global_pooling"
    type: "bool"
    default_value {
      b: false
    }
    description: "From Caffe. If global_pooling then it will pool over the size of the bottom by doing shape.h = bottom->height and shape_w = bottom->width."
  }
  attr {
    name: "dilation_rate"
    type: "list(int)"
    description: "Sequence of N ints >= 1. Specifies the filter upsampling/input downsampling rate."
  }
  attr {
    name: "window_shape"
    description: "Shape `[1, depth, height, wide, 1]`."
    type: "list(int)"
  }
  attr {
    name: "strides"
    type: "list(int)"
    description: "1-D tensor of length N.  [1, stride_deep, stride_height, stride_weight, 1]"
  }
  attr {
    name: "pooling_type"
    type: "string"
    description: "The type of pooling type to use."
    allowed_values {
      list {
        s: "MAX"
        s: "AVG"
      }
    }
  }
  attr {
    name: "padding"
    type: "string"
    description: "The type of padding algorithm to use."
    allowed_values {
      list {
        s: "SAME"
        s: "VALID"
      }
    }
  }
  attr {
    name: "data_format"
    type: "string"
    default_value {
      s: "NHWC"
    }
    allowed_values {
      list {
        s: "NC"
        s: "NWC"
        s: "NCW"
        s: "NHWC"
        s: "NCHW"
        s: "NDHWC"
        s: "NCDHW"
      }
    }
  }
  summary: "Performs an N-D pooling operation."
  description: "tf.nn.pool defined"
}

op {
  name: "Mul"
  summary: "Returns x * y element-wise."
  description: "*NOTE*: `Mul` supports broadcasting. More about broadcasting[here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)"
}

op {
  name: "Reshape"
  attr {
    name: "shape"
    type: "shape"
    description: "The target shape of the tensor."
  }
  summary: "Reshapes a tensor."
}


op {
  name: "RNN"

}

op {
  name: "LSTM"

}

op {
  name: "GRU"

}

op {
  name: "SeparableConvolution"
  attr {
    name: "strides"
    type: "list(int)"
    description: "1-D of length 4.  The stride of the sliding window for each dimension of `input`."
  }
  attr {
    name: "padding"
    type: "string"
    description: "The type of padding algorithm to use."
    allowed_values {
      list {
        s: "SAME"
        s: "VALID"
      }
    }
  }
  attr {
    name: "data_format"
    type: "string"
    default_value {
      s: "NHWC"
    }
    description: "Specify the data format of the input and output data. With the default format \"NHWC\", the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be \"NCHW\", the data storage order of: [batch, channels, height, width]."
    allowed_values {
      list {
        s: "NHWC"
        s: "NCHW"
      }
    }
  }
}


op {
  name: "Sub"
  input_arg {
    name: "x"
    type_attr: "T"
  }
  input_arg {
    name: "y"
    type_attr: "T"
  }
  output_arg {
    name: "z"
    type_attr: "T"
  }
  attr {
    name: "axis"
    type: "int"
  }
  summary: "Returns x - y element-wise."
  description: "*NOTE*: `Add` supports broadcasting."
}


op {
  name: "LRN"
  attr {
    name: "size"
    type: "int"
    description: "0-D.  Half-width of the 1-D normalization window."
  }

  attr {
    name: "alpha"
    type: "float"
    description: "A scale factor, usually positive."
  }

  attr {
    name: "beta"
    type: "float"
    description: "An exponent."
  }

  attr {
    name: "bias"
    type: "float"
    description: "An offset (usually positive to avoid dividing by 0)."
  }
  summary: "Local Response Normalization."
  description: "The 4-D `input` tensor is treated as a 3-D array of 1-D vectors (along the last dimension), and each vector is normalized independently.  Within a given vector, each component is divided by the weighted, squared sum of inputs within `size`.  In detail, sqr_sum[a, b, c, d] = sum(input[a, b, c, d - size : d + size + 1] ** 2) output = input / (bias + alpha * sqr_sum) ** beta For details, see [Krizhevsky et al., ImageNet classification with deep convolutional neural networks (NIPS 2012)](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks)."
}


op {
  name: "Squeeze"
  attr {
    name: "squeeze_dims"
    type: "list(int)"
    default_value {
      list {
      }
    }
    description: "If specified, only squeezes the dimensions listed. The dimension index starts at 0. It is an error to squeeze a dimension that is not 1."
  }
  summary: "Removes dimensions of size 1 from the shape of a tensor."
  description: "Given a tensor `input`, this operation returns a tensor of the same type with all dimensions of size 1 removed."
}


op {
  name: "DepthwiseConv"
  attr {
    name: "strides"
    type: "list(int)"
    description: "1-D of length 4.  The stride of the sliding window for each dimension of `input`."
  }
  attr {
    name: "padding"
    type: "string"
    description: "The type of padding algorithm to use."
    allowed_values {
      list {
        s: "SAME"
        s: "VALID"
      }
    }
  }
  attr {
    name: "data_format"
    type: "string"
    default_value {
      s: "NHWC"
    }
    description: "Specify the data format of the input and output data. With the default format \"NHWC\", the data is stored in the order of: [batch, height, width, channels]. Alternatively, the format could be \"NCHW\", the data storage order of: [batch, channels, height, width]."
    allowed_values {
      list {
        s: "NHWC"
        s: "NCHW"
      }
    }
  }
  summary: "Computes a 2-D depthwise convolution given 4-D `input` and `filter` tensors."
  description: "Given an input tensor of shape `[batch, in_height, in_width, in_channels]` and a filter / kernel tensor of shape `[filter_height, filter_width, in_channels, channel_multiplier]`, containing `in_channels` convolutional filters of depth 1, `depthwise_conv2d` applies a different filter to each input channel (expanding from 1 channel to `channel_multiplier` channels for each), then concatenates the results\ntogether. Thus, the output has `in_channels * channel_multiplier` channels.\n\n```\nfor k in 0..in_channels-1\n  for q in 0..channel_multiplier-1\n    output[b, i, j, k * channel_multiplier + q] =\n      sum_{di, dj} input[b, strides[1] * i + di, strides[2] * j + dj, k] *\n                        filter[di, dj, k, q]``` Must have `strides[0] = strides[3] = 1`.  For the most common case of the same horizontal and vertices strides, `strides = [1, stride, stride, 1]`."
}