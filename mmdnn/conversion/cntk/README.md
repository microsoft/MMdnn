# CNTK README

## Usage

Currently we only implemented the IR -> CNTK part. Any contribution to CNTK parser (CNTK -> IR) is welcome.

### Convert models from IR to CNTK code snippet

The generated CNTK model code snippet can restore weights from IR weights file directly, but we need the tensors' shape information to infer some parameters.

```bash
$ python -m mmdnn.conversion._script.IRToCode --dstModelFormat cntk --IRModelPath inception_v3.pb --dstModelPath cntk_inception_v3.py --IRWeightPath inception_v3.npy

Parse file [inception_v3.pb] with binary format successfully.
Target network code snippet is saved as [cntk_inception_v3.py].
```

### Convert models from IR to CNTK model

After generating the CNTK code snippet, you can convert the code and IR weights file to CNTK original model for further usage.

```bash
$ python -m mmdnn.conversion.examples.cntk.imagenet_test -n cntk_inception_v3.py -w inception_v3.npy --dump cntk_inception_v3.dnn

CNTK model file is saved as [cntk_inception_v3.dnn], generated by [cntk_inception_v3.py] and [inception_v3.npy].
```

## Develop version

Ubuntu 16.04 with

- CNTK gpu 2.2

@ 11/21/2017

## Limitation

- Main dataflow in network is NHWC (channel last) format, but CNTK CNN-related operators take NCHW (channel first) format data. So we transpose the data format before and after each CNN-related operators (such as Convolution, Pooling, LRN, BN and so on). The data transpose sacrifices some computing performance. There is some methods to reduce the performance gap.

    1. Like PyTorch and MXNet emitter, change the main dataflow format to NCHW (channel last) and tranpose the weights in IR-Code step.

    1. Remove unnecessary transpose during building the network.

- Currently no RNN-related operations support
